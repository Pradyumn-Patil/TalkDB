# app.py
import os
import pandas as pd
from flask import Flask, request, jsonify, render_template
import google.generativeai as genai
import json
import logging

# Set up basic logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

try:
    from dotenv import load_dotenv
except ImportError:
    logger.warning("python-dotenv not installed. Will try to use environment variables directly.")
    load_dotenv = lambda: None

# ==============================================================================
# --- Configuration Section ---
# ==============================================================================
EXCEL_FILE = '/Users/pradyumn/Desktop/DTE_admission_chatbot/EnggAdmissions2024.xlsx'

# --- Key Column Names (must match your Excel file) ---
INSTITUTE_CODE_COLUMN = 'InstituteCode'
INSTITUTE_NAME_COLUMN = 'InstituteName'
INSTITUTE_TYPE_COLUMN = 'Status'
REGION_COLUMN = 'RegionName'
DISTRICT_COLUMN = 'DistrictName'
PROGRAM_ID_COLUMN = 'ProgramID'
AUTONOMY_COLUMN = 'Autonomu'
MINORITY_COLUMN = 'Minority'
# ==============================================================================

app = Flask(__name__)

def load_and_prepare_data():
    """Loads and preprocesses the admissions data from Excel file."""
    try:
        if not os.path.exists(EXCEL_FILE):
            logger.error(f"Excel file not found: {EXCEL_FILE}")
            raise FileNotFoundError(f"Excel file not found: {EXCEL_FILE}")

        # Read Excel file
        df = pd.read_excel(EXCEL_FILE)
        logger.info(f"Excel file loaded successfully. Shape: {df.shape}")
        logger.info(f"Available columns: {df.columns.tolist()}")
        
        # Clean column names and verify required columns
        df.columns = df.columns.str.strip()
        required_columns = [INSTITUTE_CODE_COLUMN, INSTITUTE_NAME_COLUMN, INSTITUTE_TYPE_COLUMN, 
                          REGION_COLUMN, DISTRICT_COLUMN, PROGRAM_ID_COLUMN, AUTONOMY_COLUMN, 
                          MINORITY_COLUMN]
        
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"Missing required columns: {missing_columns}")
        
        # Create institute summary
        institute_summary = df.groupby([INSTITUTE_CODE_COLUMN, INSTITUTE_NAME_COLUMN, 
                                      INSTITUTE_TYPE_COLUMN, REGION_COLUMN, DISTRICT_COLUMN]).agg({
            PROGRAM_ID_COLUMN: 'count'  # Count number of programs per institute
        }).reset_index()

        # Rename columns for clarity
        institute_summary.rename(columns={
            PROGRAM_ID_COLUMN: 'Total_Programs'
        }, inplace=True)

        # Add autonomy and minority status
        institute_summary = institute_summary.merge(
            df[[INSTITUTE_CODE_COLUMN, AUTONOMY_COLUMN, MINORITY_COLUMN]].drop_duplicates(),
            on=INSTITUTE_CODE_COLUMN,
            how='left'
        )

        logger.info(f"Successfully created institute summary. Shape: {institute_summary.shape}")
        logger.info(f"Number of unique institutes: {institute_summary[INSTITUTE_CODE_COLUMN].nunique()}")
        return df, institute_summary
        
    except Exception as e:
        logger.error(f"Error loading data: {str(e)}")
        logger.error(f"Please check your Excel file and column names.")
        return None, None

def execute_analysis_script(script):
    """Executes a Python script generated by the LLM and expects a dictionary as output."""
    try:
        if full_data is None or institute_data is None:
            logger.error("Data not loaded properly")
            return None, "Data not loaded properly. Please check the Excel file."
            
        local_scope = {
            'df': full_data.copy(),
            'institute_df': institute_data.copy(),
            'pd': pd
        }
        
        exec(script, {'pd': pd}, local_scope)
        output = local_scope.get('final_output')
        
        if output and isinstance(output, dict) and 'answer' in output:
            # Convert DataFrame in 'data' to list of dictionaries if present
            if 'data' in output and isinstance(output['data'], pd.DataFrame):
                output['data'] = output['data'].to_dict('records')
            return output, None
        else:
            logger.error("Script did not produce expected output format")
            return None, "The analysis did not produce a valid response format"
            
    except Exception as e:
        logger.error(f"Error executing script: {str(e)}")
        return None, f"Error analyzing data: {str(e)}"

@app.route('/')
def index():
    """Renders the chat interface."""
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    """Handle chat messages and generate responses."""
    try:
        if full_data is None or institute_data is None:
            logger.error("Data not loaded")
            return jsonify({'error': 'Data not properly loaded. Please check the Excel file.'}), 500

        if not model:
            logger.error("AI model not configured")
            return jsonify({'error': 'AI model not configured. Please check the API key.'}), 500
            
        user_query = request.json.get('query')
        if not user_query:
            logger.error("No query provided")
            return jsonify({'error': 'No query provided'}), 400

        logger.debug(f"Processing query: {user_query}")
        
        
        # Create prompt
        prompt = f"""
        You are an expert Python data analyst working with REAL engineering college admission data. 
        
        ⚠️ CRITICAL RULES:
        1. NEVER create sample data or example dataframes
        2. ONLY use the existing 'df' and 'institute_df' dataframes
        3. DO NOT include any DataFrame creation code
        4. DO NOT use any hardcoded data
        5. DO NOT define functions - write direct analysis code
        6. DO NOT include print statements
        7. ALWAYS format numbers with thousands separator
        8. ALWAYS return properly formatted answer with newlines

        USER QUESTION: "{user_query}"

        You have access to these EXISTING dataframes:

        1. `df`: Main dataframe with actual program data
           Shape: {full_data.shape}
           Columns: {full_data.columns.tolist()}
           Contains:
           - ProgramID: Program identifier (e.g., BETECH1G)
           - InstituteCode: Unique code for each institute
           - InstituteName: Name of the institute
           - DistrictName: District where institute is located
           - RegionName: Region of the institute
           - Status: Type of institute (Government, Private, University Department, etc.)
           - Autonomu: Autonomy status (Autonomous/Non-Autonomous)
           - Minority: Minority status (Minority/Non-Minority)

        2. `institute_df`: Pre-aggregated institute summary from REAL data
           Shape: {institute_data.shape}
           Columns: {institute_data.columns.tolist()}
           Contains:
           - InstituteCode, InstituteName: Institute identifiers
           - Status: Type of institute
           - RegionName, DistrictName: Location details
           - Total_Programs: Number of programs offered
           - Autonomu: Autonomy status
           - Minority: Minority status

        CORRECT EXAMPLE (comparing college types):
        ```python
        # Get program counts by status
        status_summary = institute_df.groupby('Status').agg({{
            'InstituteCode': 'count',
            'Total_Programs': 'sum'
        }}).reset_index()
        
        # Format the answer with proper newlines and thousands separators
        answer = "Analysis of Colleges by Status:\\n\\n"
        for _, row in status_summary.iterrows():
            answer += f"{{row['Status']}}:\\n"
            answer += f"- Number of Colleges: {{row['InstituteCode']:,}}\\n"
            answer += f"- Total Programs: {{row['Total_Programs']:,}}\\n\\n"
        
        final_output = {{
            "answer": answer,
            "data": status_summary
        }}
        ```

        INCORRECT EXAMPLES (NEVER DO THESE):
        ```python
        # ❌ WRONG - Never create sample data
        data = {{'InstituteCode': ['A1', 'A2'], 'Status': ['Government', 'Private']}}
        df = pd.DataFrame(data)
        
        # ❌ WRONG - Never define functions
        def analyze_data(df):
            return df.groupby('Status').count()
            
        # ❌ WRONG - Never use print statements
        print("Analysis results:")
        print(result)
        ```

        Generate ONLY the analysis script using the EXISTING dataframes. Focus on clear formatting with proper newlines (\\n) and thousands separators (:,).
        """
        
        logger.debug("Calling Gemini API")
        response = model.generate_content(prompt)
        
        if not response.text:
            logger.error("Empty response from Gemini")
            return jsonify({'error': 'No response from AI model'}), 500
            
        generated_script = response.text.strip().replace('```python', '').replace('```', '')
        logger.debug(f"Generated script:\n{generated_script}")
        
        # Execute the script
        result, error = execute_analysis_script(generated_script)
        
        if error:
            logger.error(f"Script execution error: {error}")
            return jsonify({'error': error}), 500
            
        # Format response
        if result and isinstance(result, dict):
            if 'data' in result and result['data']:
                result['data'] = {
                    "headers": list(result['data'][0].keys()) if result['data'] else [],
                    "rows": result['data']
                }
            logger.info("Successfully processed chat request")
            return jsonify(result)
        else:
            logger.error("Invalid result format")
            return jsonify({'error': 'Invalid response format from analysis'}), 500

    except Exception as e:
        logger.error(f"Unexpected error in chat endpoint: {str(e)}")
        return jsonify({'error': f'An unexpected error occurred: {str(e)}'}), 500

# --- AI Setup ---
try:
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        load_dotenv()
        api_key = os.environ.get("GEMINI_API_KEY")

    if api_key:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        logger.info("Gemini API configured successfully")
    else:
        model = None
        logger.error("GEMINI_API_KEY not found in environment variables")
except Exception as e:
    logger.error(f"Error configuring Gemini API: {e}")
    model = None

# Load data on startup
logger.info("Loading data on startup...")
full_data, institute_data = load_and_prepare_data()

if __name__ == '__main__':
    if not os.path.exists('templates'):
        os.makedirs('templates')
        
    if full_data is not None:
        logger.info("Starting Flask server...")
        app.run(debug=True)
    else:
        logger.error("Application not starting due to data loading errors")
        print("Application will not start because the Excel file could not be read. Please check the errors above.")